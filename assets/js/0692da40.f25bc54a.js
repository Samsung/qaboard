"use strict";(self.webpackChunkApache_2_0=self.webpackChunkApache_2_0||[]).push([[2496],{3905:function(e,t,n){n.d(t,{Zo:function(){return m},kt:function(){return d}});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},m=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),p=c(n),d=i,f=p["".concat(l,".").concat(d)]||p[d]||u[d]||r;return n?a.createElement(f,o(o({ref:t},m),{},{components:n})):a.createElement(f,o({ref:t},m))}));function d(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,o[1]=s;for(var c=2;c<r;c++)o[c]=n[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},1929:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},contentTitle:function(){return c},metadata:function(){return m},toc:function(){return u},default:function(){return d}});var a=n(7462),i=n(3366),r=(n(7294),n(3905)),o=n(4996),s=["components"],l={id:"computing-quantitative-metrics",sidebar_label:"Metrics",title:"Computing quantitative metrics"},c=void 0,m={unversionedId:"computing-quantitative-metrics",id:"computing-quantitative-metrics",title:"Computing quantitative metrics",description:"Algorithms are usually evaluated using KPIs / Objective Figures of Merit / metrics. To make sure QA-Board's web UI displays them:",source:"@site/docs/computing-quantitative-metrics.md",sourceDirName:".",slug:"/computing-quantitative-metrics",permalink:"/qaboard/docs/computing-quantitative-metrics",editUrl:"https://github.com/Samsung/qaboard/edit/master/website/docs/docs/computing-quantitative-metrics.md",tags:[],version:"current",frontMatter:{id:"computing-quantitative-metrics",sidebar_label:"Metrics",title:"Computing quantitative metrics"},sidebar:"docs",previous:{title:"Outputs",permalink:"/qaboard/docs/creating-and-viewing-outputs-files"},next:{title:"Configurations",permalink:"/qaboard/docs/specifying-configurations"}},u=[{value:"Failed runs",id:"failed-runs",children:[],level:2},{value:"Rich metrics",id:"rich-metrics",children:[],level:2},{value:"Metrics shown as a &quot;run-time&quot; configuration",id:"metrics-shown-as-a-run-time-configuration",children:[],level:2}],p={toc:u};function d(e){var t=e.components,n=(0,i.Z)(e,s);return(0,r.kt)("wrapper",(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Algorithms are usually evaluated using KPIs / Objective Figures of Merit / metrics. To make sure QA-Board's web UI displays them:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"run()")," should return a dict of metrics:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'title="qa/main.py"',title:'"qa/main.py"'},'def run():\n    # --snip--\n    return {\n        "loss": loss\n    }\n')),(0,r.kt)("div",{className:"admonition admonition-tip alert alert--success"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"}))),"tip")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"Alternatively, you can also write your metrics as JSON in ",(0,r.kt)("inlineCode",{parentName:"p"},"ctx.obj['output_directory'] / metrics.json"),"."))),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},"Describe your metrics in ",(0,r.kt)("em",{parentName:"li"},"qa/metrics.yaml"),". Here is an example")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml",metastring:'title="qa/metrics.yaml (location from qaboard.yaml: outputs.metrics)"',title:'"qa/metrics.yaml',"(location":!0,from:!0,"qaboard.yaml:":!0,'outputs.metrics)"':!0},"available_metrics:\n  loss:  # the fields below are all optionnal\n    label: Loss function     # human-readable name\n    short_label: Loss        # somes part of the UI are better with thin labels...\n    smaller_is_better: true  # default: true\n    target: 0.01             # plots in the UI will compare KPIs versus a target if given\n    target_passfail: false   # the UI will render the metric as green/red depending on above/below the target\n    # when displaying results in the UI, you often want to change units\n    # suffix: ''   # e.g. \"%\"...\n    # scale: 1     # e.g. 100 to convert [0-1] to percents...\n    # by default we try to show 3 significant digits, but you can change it with\n    # precision: 3\n\n# at the end of the file add your metrics to\n# default_metric/main_metrics/summary_metrics\n")),(0,r.kt)("p",null,"If it all goes well you get:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Tables to compare KPIs per-input across versions:")),(0,r.kt)("img",{alt:"https://qa/tof/swip_tof/commit/42778afb1fea31e19c00291a2a52bf490e3acc2c?reference=a451dda9cfdd586702ead95f436e41c5b074ebfa&selected_views=summary&filter=old",src:(0,o.Z)("img/quantitative-metrics.png")}),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Summaries:")),(0,r.kt)("img",{alt:"https://qa/tof/swip_tof/commit/42778afb1fea31e19c00291a2a52bf490e3acc2c?reference=a451dda9cfdd586702ead95f436e41c5b074ebfa&selected_views=summary&filter=old",src:(0,o.Z)("img/summary-metrics.png")}),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Metrics integrated in the visualizations:"),(0,r.kt)("img",{alt:"https://qa/tof/swip_tof/commit/42778afb1fea31e19c00291a2a52bf490e3acc2c?reference=a451dda9cfdd586702ead95f436e41c5b074ebfa&selected_views=output-list&filter=old%20low%204ta",src:(0,o.Z)("img/quantitative-metrics-on-viz.png")})),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"and evolution over time per branch..."))),(0,r.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"We plan on not requiring you to define all metrics ahead of time..."))),(0,r.kt)("h2",{id:"failed-runs"},"Failed runs"),(0,r.kt)("p",null,"The metric ",(0,r.kt)("inlineCode",{parentName:"p"},"is_failed"),' is boolean. If true, QA-Board will consider the run as "failed".\nThe main uses cases are:'),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"highlight in the UI"),(0,r.kt)("li",{parentName:"ul"},"failing runs that don't achieve a basic target quality (or where things just crash...)"),(0,r.kt)("li",{parentName:"ul"},"simplifying the control flow, instead of raising an exception from ",(0,r.kt)("inlineCode",{parentName:"li"},"run()")),(0,r.kt)("li",{parentName:"ul"},"remembering if the ",(0,r.kt)("inlineCode",{parentName:"li"},"run")," was successful, when users split between ",(0,r.kt)("inlineCode",{parentName:"li"},"run/postprocess")," stages")),(0,r.kt)("h2",{id:"rich-metrics"},"Rich metrics"),(0,r.kt)("p",null,"If you return string metrics, they will be shown the UI's tables and cards like this:"),(0,r.kt)("img",{alt:"https://qa/tof/swip_tof/commit/42778afb1fea31e19c00291a2a52bf490e3acc2c?reference=a451dda9cfdd586702ead95f436e41c5b074ebfa&selected_views=output-list&filter=old%20low%204ta",src:(0,o.Z)("img/rich-metrics-in-card.png")}),(0,r.kt)("p",null,'You can return "rich" metrics to customize the display:'),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'def run(context):\n    # ...\n    metrics = {\n        "loss": 1.345, # regular metric, loss has to be defined in qa/metrics.yaml\n        "status": "unstable", # string metric\n        # you can have more complex metrics..\n        "rich_status": {\n            "text": "unstable",\n            # link to somewhere\n            "href": "https://example.com",\n            "icon": "settings", # choose from https://blueprintjs.com/docs/#icons\n            "intent": "WARNING", # or PRIMARY|SUCCESS|WARNING\n            # the rendered "tag" supports all parameters of\n            #   https://blueprintjs.com/docs/#core/components/tag\n            # like "style" for CSS properties, large, minimal....\n        } \n    }\n    return metrics\n')),(0,r.kt)("h2",{id:"metrics-shown-as-a-run-time-configuration"},'Metrics shown as a "run-time" configuration'),(0,r.kt)("p",null,"It is possible to add at run-time parameters to the run. The use-cases are:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"making very visible a few key parameters")," nested deep in a config-file, and enabling ",(0,r.kt)("strong",{parentName:"li"},"filtering")," by them"),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"displaying links")," next to runs, grouped with the configuration (and not the metrics like above!). Users often use those badges to do deep-learning inference on QA-Board, and easily link back to the training page, managed by a different product. They'll give a model ID as configuration, their ",(0,r.kt)("inlineCode",{parentName:"li"},"run()")," will fetch the training page URL, and it enables smooth workflows.")),(0,r.kt)("img",{alt:"https://qa/tof/swip_tof/commit/42778afb1fea31e19c00291a2a52bf490e3acc2c?reference=a451dda9cfdd586702ead95f436e41c5b074ebfa&selected_views=output-list&filter=old%20low%204ta",src:(0,o.Z)("img/run-badges.png")}),(0,r.kt)("p",null,"To make it happen, return in your metrics a ",(0,r.kt)("inlineCode",{parentName:"p"},"params")," key:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'def run(context)\n    return {\n        # ...\n        "params": {\n            # in the UI users will see "mode" as part of the run parameters\n            "mode": "GAN",\n            # they will also see a "badge" linking to the model training page:\n            "badges": [\n                {\n                    "text": "Training",\n                    "href": "https://wandb/run/<some-id>",\n                    "icon": "settings",\n                    # for more info on available key see above\n                }\n            ]\n        }\n    }\n')))}d.isMDXComponent=!0}}]);